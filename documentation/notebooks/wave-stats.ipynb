{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_17251773448334753583() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_17251773448334753583()\">Toggle show/hide</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove_input",
     "remove_markdown"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table{\n",
       "    display: block\n",
       "}\n",
       "\n",
       "table th {\n",
       "text-align: left;\n",
       "}\n",
       "\n",
       "table td {\n",
       "text-align: left;\n",
       "}\n",
       "\n",
       "table img {\n",
       "border: 1px solid black;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table{\n",
    "    display: block\n",
    "}\n",
    "\n",
    "table th {\n",
    "text-align: left;\n",
    "}\n",
    "\n",
    "table td {\n",
    "text-align: left;\n",
    "}\n",
    "\n",
    "table img {\n",
    "border: 1px solid black;\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/usgs.png\" style=\" padding-top: 26px; float: left\"/>\n",
    "<img src=\"./images/WaveLabLogo.png\" style=\"float: left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the following assumptions when calculating wave statistics:\n",
    "\n",
    "1. Linear Wave Theory is applicable.\n",
    "2. Mean water depth and waves are sufficiently constant over each 17 minute time series chunk (4096 points of data collected at 4 Hz) in order to yield meaningful wave statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pytz\n",
    "\n",
    "def plot_graph(x_data, y_data, title, x_label, y_label, size, name):\n",
    "    \n",
    "    _, ax = plt.subplots(figsize=size)\n",
    "    ax.plot(x_data,y_data)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    file_name = './images/%s.png' % name\n",
    "    plt.savefig(file_name)\n",
    "    return file_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from wavelab.utilities.nc import (get_pressure, \n",
    "                                  get_air_pressure, \n",
    "                                  get_time, \n",
    "                                  get_datetimes,\n",
    "                                  get_variable_attr,\n",
    "                                  get_global_attribute)\n",
    "\n",
    "sea_file = '../data/1_NYRIC_wv.nc'\n",
    "baro_file = '../data/1_NYRIC_bp.nc'\n",
    "\n",
    "# Load all of the data\n",
    "sea_pressure_data = get_pressure(sea_file)\n",
    "sea_milli = get_time(sea_file)\n",
    "sea_date_times = get_datetimes(sea_file)\n",
    "\n",
    "baro_pressure_data = get_air_pressure(baro_file)\n",
    "baro_milli = get_time(baro_file)\n",
    "baro_date_times = get_datetimes(baro_file)\n",
    "\n",
    "# Interpolate the air pressure\n",
    "baro_interp = np.interp(sea_milli, baro_milli, baro_pressure_data)\n",
    "\n",
    "# Slice the data accordingly\n",
    "itemindex = np.where(~np.isnan(baro_interp))\n",
    "begin = itemindex[0][0]\n",
    "end = itemindex[0][len(itemindex[0]) - 1]\n",
    "corrected_pressure = sea_pressure_data[begin:end] - baro_interp[begin:end]\n",
    "corrected_time = sea_milli[begin:end]\n",
    "corrected_date_times = sea_date_times[begin:end]\n",
    "\n",
    "#Get sensor orifice and land surface elevation\n",
    "sensor_orifice1 = get_global_attribute(sea_file, 'sensor_orifice_elevation_at_deployment_time')\n",
    "sensor_orifice2 = get_global_attribute(sea_file, 'sensor_orifice_elevation_at_retrieval_time')\n",
    "land_surface1 = get_global_attribute(sea_file, 'initial_land_surface_elevation')\n",
    "land_surface2 = get_global_attribute(sea_file, 'final_land_surface_elevation')\n",
    "orifice_elev = np.linspace(sensor_orifice1,sensor_orifice2,len(corrected_date_times))\n",
    "land_elev = np.linspace(land_surface1,land_surface2,len(corrected_date_times))\n",
    "\n",
    "def extract_level_accuracy(fname, attr):\n",
    "    try:\n",
    "        error = get_variable_attr(fname, attr, 'instrument_level_accuracy_in_meters')\n",
    "    except:\n",
    "        try:\n",
    "            instrument = get_variable_attr(fname, attr, 'instrument_make')\n",
    "        except:\n",
    "            instrument = get_global_attribute(fname, 'sea_pressure_instrument_make')\n",
    "        if instrument == 'TruBlue' or instrument == 'Level TROLL':\n",
    "            error = 0.0106679996\n",
    "        if instrument == 'Hobo':\n",
    "            error = 0.021335999\n",
    "\n",
    "    return error\n",
    "\n",
    "instrument_level_accuracy = extract_level_accuracy(sea_file, 'sea_pressure') + \\\n",
    "    extract_level_accuracy(baro_file, 'air_pressure') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the corrected sea pressure time series into chunks of 4096 points\n",
    "(approximately 17 minutes of 4 Hz data) with each chunk overlapping the preceding chunk\n",
    "by 2048 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 2048\n",
    "start_index = 0\n",
    "end_index = 4096\n",
    "p_chunks = []\n",
    "t_chunks = []\n",
    "dt_chunks = []\n",
    "elev_chunks = []\n",
    "orifice_chunks = []\n",
    "\n",
    "while end_index < len(corrected_pressure):\n",
    "    p_chunks.append(corrected_pressure[start_index:end_index])\n",
    "    t_chunks.append(corrected_time[start_index:end_index])\n",
    "    dt_chunks.append(corrected_date_times[start_index:end_index])\n",
    "    orifice_chunks.append(orifice_elev[start_index:end_index])\n",
    "    elev_chunks.append(land_elev[start_index:end_index])\n",
    "    start_index += step\n",
    "    end_index += step\n",
    "    \n",
    "og_pchunks = [x for x in p_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Pressure and Water Level Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the linear trend from each pressure time series chunk. The time series\n",
    "of a single 4096-point chunk with the trend removed is plotted below . We plot the 5th\n",
    "chunk from the full pressure time series and continue to use this chunk for illustrative\n",
    "purposes throughout the remainder of this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(p_chunks)):\n",
    "    coeff = np.polyfit(t_chunks[x],p_chunks[x],1)\n",
    "    static_p = coeff[1] + coeff[0]*t_chunks[x]\n",
    "    p_chunks[x] = p_chunks[x] - static_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,5))\n",
    "ax1.plot(dt_chunks[5], corrected_pressure[8192:12288])\n",
    "ax1.set_title('Before Detrend')\n",
    "ax2.plot(dt_chunks[5], p_chunks[4])\n",
    "ax2.set_title('After Detrend')\n",
    "detrend_img = './images/detrend.png'\n",
    "plt.savefig(detrend_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./images/detrend.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"<img src='\" + detrend_img + \"' />\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the power spectral density of each pressure chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters are number of samples in segment and sampling time step in seconds\n",
    "ogfreqs = np.fft.rfftfreq(4096,d=1/4.0)\n",
    "ogfreqs = ogfreqs[1:]\n",
    "psd_amps = []\n",
    "for x in p_chunks:\n",
    "    fft = (abs(np.fft.rfft(x))**2 / (len(x)/2)) / 4.0\n",
    "    fft = fft[1:]\n",
    "    psd_amps.append(fft)\n",
    "   \n",
    "psd_amps = np.array(psd_amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "spectra_graph =  plot_graph(ogfreqs, \n",
    "           psd_amps[4].real, \n",
    "           'Pressure Power Spectral Density of one 4096-point chunk', \n",
    "           'Frequency, Hz', \n",
    "           'Power spectral density, dbar^2/Hz', \n",
    "           (10,5),\n",
    "            'single_spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./images/single_spectra.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"<img src='\" + spectra_graph + \"' />\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Band average every 16 bands and center them on the average of each band's\n",
    "frequencies in order to increase the degrees of freedom and narrow the confidence\n",
    "intervals of the spectral estimates. Then, filter all energy that is greater than 1hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_freqs = []\n",
    "got_freqs = False\n",
    "df = 32\n",
    "\n",
    "psd_avg_amps = []\n",
    "\n",
    "for x in range(0,len(psd_amps)):\n",
    "    new_amps = []\n",
    "    step, index = int(df/2), 0\n",
    "    \n",
    "    while index < len(ogfreqs):\n",
    "        if got_freqs == False:\n",
    "            new_freqs.append(np.average(ogfreqs[np.arange(index, index+step)]))\n",
    "        \n",
    "        new_amps.append(np.average(psd_amps[x][np.arange(index, index+step)]))    \n",
    "        index += step;\n",
    "            \n",
    "    if got_freqs == False:\n",
    "        got_freqs = True\n",
    "\n",
    "    psd_avg_amps.append(np.array(new_amps))\n",
    "        \n",
    "#Cut off frequency within desired range (1 second to 1 minute)\n",
    "freqs = np.array(new_freqs)\n",
    "cutoff = np.where((freqs<=1.0) & (freqs>=0.033333333333))\n",
    "\n",
    "freqs = freqs[cutoff]\n",
    "psd_avg_amps = [psd_avg_amps[x][cutoff].real for x in range(0, len(psd_avg_amps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "band_spec_graph =  plot_graph(freqs, \n",
    "           psd_avg_amps[4].real, \n",
    "           'Band Averaged PSD', \n",
    "           'Frequency, Hz', \n",
    "           'Power spectral density, dbar^2/Hz', \n",
    "           (10,5),\n",
    "            'band_spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./images/band_spectra.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"<img src='\" + band_spec_graph + \"' />\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the 90% confidence intervals of each spectral estimate. The following is\n",
    "a graph of the preceding spectral estimate with a higher and lower bound of confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "x_range = [freqs for x in range(0,3)]\n",
    "df = 32\n",
    "ci = .9\n",
    "upper = psd_avg_amps[4]*df/stats.chi2.ppf((1 - ci)/2.0, df)\n",
    "lower = psd_avg_amps[4]*df/stats.chi2.ppf((1 + ci)/2.0, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(x_range[0], psd_avg_amps[4], color='blue', label='Original Estimate')\n",
    "ax.plot(x_range[0], upper, color='green', label='Upper 95% Confidence Bound')\n",
    "ax.plot(x_range[0], lower, color='red', label='Lower 95% Confidence Bound')\n",
    "ax.set_title('90% Confidence Intervals of Power Spectral Density')\n",
    "ax.set_xlabel('Frequency, Hz')\n",
    "ax.set_ylabel('Power spectral density, dbar^2/Hz')\n",
    "plt.legend()\n",
    "\n",
    "cf_img = './images/cf_intervals.png'\n",
    "plt.savefig(cf_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./images/cf_intervals.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"<img src='\" + cf_img + \"' />\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the wavenumber ($\\hphantom{`}k\\hphantom{`}$) for each frequency ($\\hphantom{`}\\omega\\hphantom{`}$) using the dispersion\n",
    "relation $\\hphantom{`}ω2 = g ∗ k ∗ tanh(k ∗ h)\\hphantom{`}$ where h is the mean water depth determined for the\n",
    "4096-point chunk, then calculate the pressure response function, (Jones &\n",
    "Monismith, 2007) using the following equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hphantom{`}\\Large k_{p}(z) = \\frac{cosh(z * k)}{cosh(h * k)}\\hphantom{`}$ <br /><br />\n",
    "Where: <br />\n",
    "$\\hphantom{`}z\\hphantom{`}$ = Height of the pressure transducer off the sea floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------Calculate k_p(z) for the 4096-point chunk data\n",
    "from wavelab.processing.pressure_to_depth import hydrostatic_method, omega_to_k\n",
    "\n",
    "instrument_height = [np.abs(np.mean(x) - np.mean(y)) for x,y in zip(elev_chunks, orifice_chunks)]\n",
    "water_depth = [np.mean(hydrostatic_method(x, \"salt\")) + y for x,y in zip(og_pchunks, instrument_height)]\n",
    "k_vals = [omega_to_k(freqs * 2.0 * np.pi, np.repeat(x,len(freqs))) for x in water_depth]\n",
    "kz_vals = [np.array(np.cosh(i*k)/np.cosh(w*k)) for w,k,i in zip(water_depth,k_vals,instrument_height)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use $\\hphantom{`}k_{p}^{2}\\hphantom{`}$ to change the pressure PSD to a water-level PSD using the following\n",
    "equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\hphantom{`}\\Large \\eta = \\frac{p}{k_{p}^{2}}\\hphantom{`}$  <b>(Jones & Monismith, 2007)</b><br /><br />\n",
    "Where: <br />\n",
    "$\\hphantom{`}p\\hphantom{`}$ = Pressure PSD<br />\n",
    "$\\hphantom{`}\\eta\\hphantom{`}$ = Water Level PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavelab.processing.wave_stats import Stats\n",
    "\n",
    "stats = Stats()\n",
    "upper_psd, lower_psd = [], []\n",
    "for x in range(0,len(psd_avg_amps)):\n",
    "    u, l = stats.psd_confidence_intervals(psd_avg_amps[x],df,.9)\n",
    "    upper_psd.append(u)\n",
    "    lower_psd.append(l)\n",
    "    \n",
    "upper_psd, lower_psd = np.array(upper_psd), np.array(lower_psd)\n",
    "\n",
    "wl_amps = [z/kz**2 for z, kz in zip(psd_avg_amps, kz_vals)]\n",
    "wl_up = [z/kz**2 for z, kz in zip(upper_psd, kz_vals)]\n",
    "wl_down = [z/kz**2 for z, kz in zip(lower_psd, kz_vals)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Wave Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate spectral moments by using the trapezoidal rule to integrate over the\n",
    "PSD using the following equation (Carter, 1982):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hphantom{`}\\Large m_{n} = \\int_{0}^{\\inf}f^{n}E(f)df\\hphantom{`}$<br /><br />\n",
    "Where: <br />\n",
    "$\\hphantom{`}m_{n}\\hphantom{`}$ = The nth spectral moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate statistics based on the water level PSD.  The following is a table of some statistics that are computed (Vrabel & Rendon, 2013):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Statistic | Equation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | Explanation |\n",
    "| ----------------------- | --- | ------------------------ |\n",
    "| Significant Wave Height (H1/3) | $\\hphantom{`}4 * \\sqrt{m_{0}}\\hphantom{`}$ | Height of the top one third of waves |\n",
    "| Top Ten Percent Wave Height (H 10%)) | $\\hphantom{`}5.091 * \\sqrt{m_{0}}\\hphantom{`}$ | Height of the top ten percent of waves |\n",
    "| Top One Percent Wave Height (H 1%) | $\\hphantom{`}6.672 * \\sqrt{m_{0}}\\hphantom{`}$ | Height of the top one percent of waves |\n",
    "| Average Zero Up-crossing Period | $\\hphantom{`}\\sqrt{\\frac{m_{0}}{m_{2}}}\\hphantom{`}$ | Length of average wave period that crosses the mean sea surface |\n",
    "| Average Wave Period | $\\hphantom{`}\\frac{m_{0}}{m_{1}}\\hphantom{`}$ | Length of average wave period |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick note:  For confidence intervals around significant wave height, we also need to account for the total level accuracy of the two instruments used to collect the data.  <b>This is not the same as total error bars, the USGS has done through testing at our <a href=\"https://water.usgs.gov/hif/\">Hyrdrologic Instrumentation Facility</a> but more in depth testing is necessary to release total error bars for our instruments.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Significant Wave Height and Average Zero Up-crossing Period\n",
    "h13, tavg, h13_up, h13_down = [], [], [], []\n",
    "\n",
    "# Account for confidence intervals computed earlier as well as combined level accuracy of both deployed instruments\n",
    "for x in range(0,len(wl_amps)):\n",
    "    h13.append(4 * np.sqrt(Stats.moment(freqs,wl_amps[x],0)))\n",
    "    h13_up.append(4 * np.sqrt(Stats.moment(freqs,wl_up[x],0)) + instrument_level_accuracy)\n",
    "    h13_down.append(4 * np.sqrt(Stats.moment(freqs,wl_down[x],0)) - instrument_level_accuracy)\n",
    "    tavg.append(Stats.moment(freqs,wl_amps[x],0)/Stats.moment(freqs,wl_amps[x],2))\n",
    "   \n",
    "final_times = []\n",
    "for x in range(0,len(t_chunks)):\n",
    "    final_times.append(np.mean(t_chunks[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a graph of significant wave height:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from wavelab.utilities.unit_conversion import convert_ms_to_date\n",
    "\n",
    "final_dt = [convert_ms_to_date(dt,pytz.UTC) for dt in final_times]\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(final_dt, h13, color='blue', label='Original Estimate')\n",
    "ax.plot(final_dt, h13_up, color='green', label='Upper 95% Confidence Bound')\n",
    "ax.plot(final_dt, h13_down, color='red', label='Lower 95% Confidence Bound')\n",
    "ax.set_title('90% Confidence Intervals for Significant Wave Height')\n",
    "ax.set_xlabel('Time in UTC')\n",
    "ax.set_ylabel('Wave Height in Meters')\n",
    "plt.legend()\n",
    "\n",
    "h13_img = './images/h13.png'\n",
    "plt.savefig(h13_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='images/h13.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"<img src='images/h13.png' />\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a graph of the average zero up-crossing period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "avg_z_png = plot_graph(final_dt, \n",
    "           tavg, \n",
    "           'Average Zero Up-crossing period', \n",
    "           'Time in UTC', \n",
    "           'Wave Period in Seconds', \n",
    "           (10,5),\n",
    "            'avg_z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='./images/avg_z.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"<img src='\" + avg_z_png + \"' />\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Carter D. J. T. (1982). Prediction of Wave Height and Period For a Constant Wind Velocity Using <br />\n",
    "&nbsp;&nbsp;the Jonswap Results. Pergamon Press Ltd., 9 No.1, 17-33. doi:0029-8018/010017-17\n",
    "    \n",
    "Earle, Marshall D. (1996). Nondirectional and Directional Wave Data Analysis Procedures. National <br />\n",
    "&nbsp;&nbsp;Data Buoy Center.\n",
    "\n",
    "Emery, William J. and Richard E. Thomson (2014), Data Analysis Methods in Physical Oceanography.\n",
    "\n",
    "Jones, N. and S. Monismith. (2007). Measuring Short Period Wind Waves in a Tidally Forced <br />\n",
    "&nbsp;&nbsp;Environment with a Subsurface Pressure Gauge. Limnology and Oceanography: Methods, 5, 317-327.\n",
    "\n",
    "SciPy (0.17.1) [Software]. (2016). SciPy, scipy.signal.welch, 1. http://www.scipy.org\n",
    "    \n",
    "Smith J. M. (2002). \"Wave Pressure Gauge Analysis with Current\". Journal of Waterway, Port, <br />\n",
    "&nbsp;&nbsp;Coastal, and Ocean Engineering, Novemeber/Decemeber 2002, 271-275. <br />\n",
    "&nbsp;&nbsp;doi:10.10161/(ASCE)0733-950X(2002)128:6(271)\n",
    "        \n",
    "Vrabel, J. and S. Rendon. (2013). Storm Surge, Unpublished Software Routine. United States <br />\n",
    "&nbsp;&nbsp;Geological Survey, personal communication."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
